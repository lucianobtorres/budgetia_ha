# pages/2_游눫_Chat_com_IA.py

import streamlit as st

# Importar AgentRunner (ajuste o caminho conforme sua estrutura)
# Assumindo que AgentRunner est치 em core ou agent_implementations
from core.agent_runner_interface import (
    AgentRunner,  # Ou importe a implementa칞칚o espec칤fica IADeFinancas
)

# --- Verifica칞칚o de Inicializa칞칚o ---
if "agent_runner" not in st.session_state or "llm_orchestrator" not in st.session_state:
    st.error(
        "Erro: O sistema de IA n칚o foi carregado corretamente. Por favor, volte  p치gina principal (app.py)."
    )
    st.stop()

# Recupera os objetos do estado da sess칚o
agent_runner: AgentRunner = st.session_state.agent_runner
llm_orchestrator = (
    st.session_state.llm_orchestrator
)  # Pode ser 칰til para mostrar status

# --- Renderiza칞칚o da P치gina de Chat ---
st.header("游눫 Converse com seu Mentor Financeiro")

# Inicializa o hist칩rico de chat espec칤fico desta p치gina no session_state
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []

# Exibe mensagens do hist칩rico
for message in st.session_state.chat_messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu치rio
if prompt := st.chat_input(
    "Como posso te ajudar com suas finan칞as hoje? (Ex: Qual meu saldo?, Adicione despesa...)"
):
    # Adiciona e exibe a mensagem do usu치rio
    st.session_state.chat_messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # --- CORRE칂츾O DO BLOCO DA IA ---
    with st.chat_message("assistant"):
        with st.spinner("IA pensando..."):
            try:
                # --- CORRE칂츾O: Usar .interagir() e passar o prompt como string ---
                # (Assumindo que seu agente 'IADeFinancas' usa a mem칩ria interna)
                output = agent_runner.interagir(prompt)

                st.markdown(output)

                # Tenta obter info do LLM
                llm_info = getattr(llm_orchestrator, "active_model_name", None)
                if llm_info:
                    st.caption(f"_Modelo: {llm_info}_")

                # Adiciona resposta da IA ao hist칩rico
                st.session_state.chat_messages.append(
                    {"role": "assistant", "content": output}
                )

                st.rerun()

            except Exception as e:
                st.error(f"Ocorreu um erro ao comunicar com a IA: {e}")
                error_msg = f"Erro: {e}"
                st.session_state.chat_messages.append(
                    {"role": "assistant", "content": error_msg}
                )
                st.rerun()
